{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TGM_U-Penn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDfWfFTsl5va"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08Jfv_feN6y7"
      },
      "source": [
        "!pip install nilearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU-F1dy9Prqd"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras_preprocessing\n",
        "import keras as k\n",
        "import keras.backend as K\n",
        "import pandas as pd\n",
        "import nibabel as nb\n",
        "import numpy as np\n",
        "import os\n",
        "from mlxtend.preprocessing import minmax_scaling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input\n",
        "from keras.callbacks import TensorBoard\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.layers import UpSampling3D\n",
        "from keras.layers.convolutional import MaxPooling3D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv3D, Conv2D\n",
        "from keras.optimizers import RMSprop, Adam, Adadelta, Adagrad, SGD\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d-mAURRPu-G"
      },
      "source": [
        "from nilearn.plotting import view_img, glass_brain, plot_anat, plot_epi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7btDsAXYPxHN"
      },
      "source": [
        "import nilearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az6UwAI4Pzgz"
      },
      "source": [
        "cd drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvWGbOnzsGx7"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXTqJtBPP1L8"
      },
      "source": [
        "def bbox(img):\n",
        "\n",
        "    r = np.any(img, axis=(1, 2))\n",
        "    c = np.any(img, axis=(0, 2))\n",
        "    z = np.any(img, axis=(0, 1))\n",
        "\n",
        "    rmin, rmax = np.where(r)[0][[0, -1]]\n",
        "    cmin, cmax = np.where(c)[0][[0, -1]]\n",
        "    zmin, zmax = np.where(z)[0][[0, -1]]\n",
        "\n",
        "    return rmin, rmax, cmin, cmax, zmin, zmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQXrp-uEP3NV"
      },
      "source": [
        "def load_train():\n",
        "    x_train = []\n",
        "    y_train1 = []\n",
        "    y_train2 = []\n",
        "    y_train3 = []\n",
        "\n",
        "    heights = pd.read_csv('Pre-operative_TCGA-GBM_Segmentations/Pre-operative_TCGA-GBM_Segmentations/TCGA_GBM_radiomicFeatures.csv')\n",
        "    \n",
        "    for i in range(102):\n",
        "      img_path1 = os.path.join('Pre-operative_TCGA-GBM_Segmentations', 'Pre-operative_TCGA-GBM_Segmentations', str(heights['ID'][i]), str(heights['ID'][i])+'_'+str(heights['Date'][i]) + '_t1.nii.gz')\n",
        "      img_path2 = os.path.join('Pre-operative_TCGA-GBM_Segmentations', 'Pre-operative_TCGA-GBM_Segmentations', str(heights['ID'][i]), str(heights['ID'][i])+'_'+str(heights['Date'][i]) + '_t1Gd.nii.gz')\n",
        "      img_path3 = os.path.join('Pre-operative_TCGA-GBM_Segmentations', 'Pre-operative_TCGA-GBM_Segmentations', str(heights['ID'][i]), str(heights['ID'][i])+'_'+str(heights['Date'][i]) + '_t2.nii.gz')\n",
        "      img_path4 = os.path.join('Pre-operative_TCGA-GBM_Segmentations', 'Pre-operative_TCGA-GBM_Segmentations', str(heights['ID'][i]), str(heights['ID'][i])+'_'+str(heights['Date'][i]) + '_flair.nii.gz')\n",
        "      img_path5 = os.path.join('Pre-operative_TCGA-GBM_Segmentations', 'Pre-operative_TCGA-GBM_Segmentations', str(heights['ID'][i]), str(heights['ID'][i])+'_'+str(heights['Date'][i]) + '_GlistrBoost_ManuallyCorrected.nii.gz')\n",
        "      im5 = niCopy of Untitled9.learn.image.math_img('img > 1', img=img_path5)\n",
        "      im1 = nb.load(img_path1)\n",
        "      im2 = nb.load(img_path2)\n",
        "      im3 = nb.load(img_path3)\n",
        "      im4 = nb.load(img_path4)\n",
        "      #im5 = nb.load(img_path5)\n",
        "      img1 = np.logical_and(im1, im5)\n",
        "      img2 = np.logical_and(im2, im5)\n",
        "      img3 = np.logical_and(im3, im5)\n",
        "      img4 = np.logical_and(im4, im5)\n",
        "      img5 = img1.get_data()\n",
        "      img6 = img2.get_data()\n",
        "      img7 = img3.get_data()\n",
        "      img8 = img4.get_data()\n",
        "      rmin1, rmax1, cmin1, cmax1, zmin1, zmax1 = bbox(img5)\n",
        "      rmin2, rmax2, cmin2, cmax2, zmin2, zmax2 = bbox(img6)\n",
        "      rmin3, rmax3, cmin3, cmax3, zmin3, zmax3 = bbox(img7)\n",
        "      rmin4, rmax4, cmin4, cmax4, zmin4, zmax4 = bbox(img8)\n",
        "      i1 = img5[rmin1:rmin1+94,cmin1:cmin1+85,zmin1:zmin1+72]\n",
        "      i2 = img6[rmin2:rmin2+94,cmin2:cmin2+85,zmin2:zmin3+72]\n",
        "      i3 = img7[rmin3:rmin3+94,cmin3:cmin3+85,zmin3:zmin3+72]\n",
        "      i4 = img8[rmin4:rmin4+94,cmin4:cmin4+85,zmin4:zmin4+72]\n",
        "      #img5 = nb.load(img_path5).get_data()\n",
        "      #plot_anat(img5)\n",
        "      #image = np.stack((i1,i2,i3,i4),axis=-1)\n",
        "      image = np.dstack((i1,i2,i3,i4))\n",
        "      print(image.shape)\n",
        "      #let1 = nilearn.image.new_img_like(im1,i1 )\n",
        "      #plot_anat(let1)\n",
        "      x_train.append(image)\n",
        "      y_train1.append(heights['TGM_p1'][i])\n",
        "      y_train2.append(heights['TGM_dw'][i])\n",
        "      y_train3.append(heights['TGM_T_1'][i])\n",
        "\n",
        "      print(i)\n",
        "    return x_train, y_train1,y_train2,y_train3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyLeBANxP8J6"
      },
      "source": [
        "z,y,e,f=load_train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5vE_7yjP_rH"
      },
      "source": [
        "z=np.asarray(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMcovODpQCSH"
      },
      "source": [
        "z.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exN-rX27QFaR"
      },
      "source": [
        "y=np.asarray(y)\n",
        "e=np.asarray(e)\n",
        "f=np.asarray(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnTdnSB-Nmsy"
      },
      "source": [
        "seed = 52\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol5ekvQMQHZB"
      },
      "source": [
        "split = train_test_split(f, e, y, z, test_size=0.2, random_state=seed)\n",
        "(Y3_train, Y3_test, Y2_train, Y2_test, Y1_train, Y1_test, X_train, X_test) = split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7clldK2wQKkO"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR9ROTIAQNHT"
      },
      "source": [
        "def nrmse(actual,predicted):\n",
        "  return (k.backend.sqrt(k.backend.mean(k.backend.square(abs(actual-predicted)))))/(k.backend.mean(actual))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PP2ib2coAsO"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOyV3_gZf0v8"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehqWNQlPwkKS"
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "cvscores = []\n",
        "for train, test in kfold.split(z, y):\n",
        "  # create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim=8, activation='relu'))\n",
        "\tmodel.add(Dense(8, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# Fit the model\n",
        "\tmodel.fit(z[train], y[train], epochs=150, batch_size=10, verbose=0)\n",
        "\t# evaluate the model\n",
        "\tscores = model.evaluate(z[test], y[test], verbose=0)\n",
        "\tprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\tcvscores.append(scores[1] * 100)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLA5Lp0pfbM9"
      },
      "source": [
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "loss_plot = []\n",
        "kfold = KFold(n_splits= 10, shuffle=True,random_state = seed)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(z, y):\n",
        "\n",
        "  # Define the model architecture\n",
        "  inputs = Input(shape=(94, 85, 288))\n",
        "\n",
        "  # convolutional layer\n",
        "\n",
        "  aa = Conv2D(16, kernel_size=(1,1),strides=(1,1),activation='relu')(inputs)\n",
        "  aa = Conv2D(16, kernel_size=(3,3),strides=(1,1),activation='relu')(aa)\n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "\n",
        "  aa = Conv2D(32, kernel_size=(3,3),strides=(1,1),activation='relu')(aa)\n",
        "  aa = Conv2D(32, kernel_size=(3,3),strides=(1,1),activation='relu')(aa)\n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "  \n",
        "  \n",
        "  ff = Flatten()(aa)\n",
        "\n",
        "  # hidden layer\n",
        "  hh = Dense(160,activation='relu')(ff)\n",
        "  hh = Dropout(0.2)(hh)\n",
        "  # output layer\n",
        "  output1 = Dense(1, activation='linear', name='TGM_T_1')(hh)\n",
        "\n",
        "\n",
        "\n",
        "  model = Model(inputs = inputs , outputs = [output1])\n",
        "\n",
        "  # compiling the sequential model\n",
        "  opt = Adagrad()\n",
        "  model.compile(loss='mse', optimizer=opt, metrics=[nrmse])\n",
        "\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  nabh = model.fit(z[train], y[train],batch_size=8, epochs=100,verbose=0)\n",
        "  loss_train = nabh.history['nrmse']\n",
        "  \n",
        "  epochs = range(0,100)\n",
        "  sns.set() # Use seaborn's default style to make attractive graphs\n",
        "  plt.rcParams['figure.dpi'] = 340 \n",
        "  plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
        "  \n",
        "  plt.title('loss vs epoch')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(z[test], y[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}%')\n",
        "  acc_per_fold.append(scores[1])\n",
        "  loss_per_fold.append(scores[0])\n",
        "  loss_plot.append(nabh.history['nrmse'])\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Mape: {acc_per_fold[i]}%')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Average scores for all folds:')\n",
        "  print(f'> Mape: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "  print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYK6PRqdfXWO"
      },
      "source": [
        "m = model.predict(X_test)\n",
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCuI90REfU2O"
      },
      "source": [
        "Y1_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn4hdLgCfSXo"
      },
      "source": [
        "plt.plot(range(0,10),'r')\n",
        "plt.scatter(m,Y1_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7Bf1Ds8rT4R"
      },
      "source": [
        "r = r2_score(Y1_test,m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAnaBDguvGrf"
      },
      "source": [
        "r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXeuHf-v5nYM"
      },
      "source": [
        "scipy.stats.spearmanr(m,Y1_test).correlation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ToUoG3FWtgv"
      },
      "source": [
        "plt.plot(loss_plot[6])\n",
        "\n",
        "plt.xlim(0, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdXKDfzHr4fS"
      },
      "source": [
        "import scipy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt7_1TCCx3EG"
      },
      "source": [
        "aa = Conv2D(16, kernel_size=(1,1),strides=(1,1),activation='relu')(inputs)\n",
        "  aa = Conv2D(16, kernel_size=(3,3),strides=(1,1),activation='relu')(aa)\n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "\n",
        "  aa = Conv2D(32, kernel_size=(3,3),strides=(1,1),activation='relu')(aa)\n",
        "  aa = Conv2D(32, kernel_size=(3,3),strides=(1,1),activation='relu')(aa)\n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "\n",
        "  ff = Flatten()(aa)\n",
        "\n",
        "  # hidden layer\n",
        "  hh = Dense(110,activation='relu')(ff)\n",
        "  hh = Dropout(0.2)(hh)\n",
        "\n",
        "  # output layer\n",
        "  output1 = Dense(1, activation='linear', name='TGM_T_1')(hh)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  batch size = 8\n",
        "\n",
        "\n",
        "  TGM_T_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY129YW9CvtD"
      },
      "source": [
        " aa = Conv2D(16, kernel_size=(1,1),strides=(1,1),activation='relu')(inputs)\n",
        "  aa = Conv2D(16, kernel_size=(1,1),strides=(1,1),activation='relu')(aa)\n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "\n",
        "  aa = Conv2D(32, kernel_size=(1,1),strides=(1,1),activation='relu')(aa)\n",
        "  aa = Conv2D(32, kernel_size=(1,1),strides=(1,1),activation='relu')(aa)\n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "  \n",
        "  \n",
        "  ff = Flatten()(aa)\n",
        "\n",
        "  # hidden layer\n",
        "  hh = Dense(180,activation='relu')(ff)\n",
        "  hh = Dropout(0.2)(hh)\n",
        "  # output layer\n",
        "  output1 = Dense(1, activation='linear', name='TGM_T_1')(hh)\n",
        "\n",
        "\n",
        "\n",
        "  model = Model(inputs = inputs , outputs = [output1])\n",
        "\n",
        "  # compiling the sequential model\n",
        "  opt = Adam()\n",
        "  model.compile(loss='mse', optimizer=opt, metrics=[nrmse])\n",
        "\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  nabh = model.fit(z[train], en[train],batch_size=8, epochs=100,verbose=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiWmdf7LCykn"
      },
      "source": [
        "en = e/1e-9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0dAXncIGr7m"
      },
      "source": [
        "def nmse(actual,predicted):\n",
        "  return k.backend.mean(k.backend.square(abs(actual-predicted)))/1e-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWqOqN7NvISy"
      },
      "source": [
        "acc_per_fold1 = []\n",
        "loss_per_fold1 = []\n",
        "loss_plot1 = []\n",
        "kfold = KFold(n_splits= 10, shuffle=True,random_state = seed)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(z, en):\n",
        "\n",
        "  # Define the model architecture\n",
        "  inputs = Input(shape=(94, 85, 288))\n",
        "\n",
        "  # convolutional layer\n",
        "\n",
        "  aa = Conv2D(8, kernel_size=(1,1),strides=(1,1),activation='relu')(inputs) \n",
        "  aa = Conv2D(8, kernel_size=(1,1),strides=(1,1),activation='relu')(aa) \n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "\n",
        "  aa = Conv2D(16, kernel_size=(1,1),strides=(1,1),activation='relu')(aa) \n",
        "  aa = Conv2D(16, kernel_size=(1,1),strides=(1,1),activation='relu')(aa) \n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "\n",
        "  ff = Flatten()(aa)\n",
        "\n",
        "  #hidden layer\n",
        "  hh = Dense(140,activation='relu')(ff) \n",
        "  hh = Dropout(0.2)(hh)\n",
        "\n",
        "  #output layer\n",
        "  output1 = Dense(1, activation='linear', name='TGM_T_1')(hh)\n",
        "\n",
        "  model1 = Model(inputs = inputs , outputs = [output1])\n",
        "\n",
        "  #compiling the sequential model\n",
        "  opt = Adam() \n",
        "  model1.compile(loss='mse', optimizer=opt, metrics=[nrmse])\n",
        "\n",
        "  #Generate a print\n",
        "  print('------------------------------------------------------------------------') \n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  nabh1 = model1.fit(z[train], en[train],batch_size=8, epochs=150,verbose=0)\n",
        "\n",
        "  loss_train1 = (nabh1.history['nrmse'])\n",
        "\n",
        "  epochs1 = range(0,150)\n",
        "  sns.set() # Use seaborn's default style to make attractive graphs\n",
        "  plt.rcParams['figure.dpi'] = 340 \n",
        "  plt.plot(epochs1, loss_train1, 'g', label=f'Fold {fold_no}')\n",
        "\n",
        "  plt.title('loss vs epoch')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model1.evaluate(z[test], en[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}%')\n",
        "  acc_per_fold1.append(scores[1])\n",
        "  loss_per_fold1.append(scores[0])\n",
        "  loss_plot1.append(nabh1.history['nrmse'])\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold1)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold1[i]} - Mape: {acc_per_fold1[i]}%')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Average scores for all folds:')\n",
        "  print(f'> Mape: {np.mean(acc_per_fold1)} (+- {np.std(acc_per_fold1)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold1)}')\n",
        "  print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e4X5KD3c3o7"
      },
      "source": [
        "m1 = model1.predict(X_test)\n",
        "m1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0pTIdAvIhBb"
      },
      "source": [
        "Y2_test/1e-9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqb0n3OkIhxQ"
      },
      "source": [
        "plt.plot(range(0,800),'r')\n",
        "plt.scatter(m1,Y2_test/1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBkD7GAYIxtf"
      },
      "source": [
        "r1 = r2_score(Y2_test/1e-9,m1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKIqB5zDI6Kp"
      },
      "source": [
        "r1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMrw_MGkI6qJ"
      },
      "source": [
        "import scipy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAfXTieqI9r-"
      },
      "source": [
        "scipy.stats.spearmanr(m1,Y2_test/1e-9).correlation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1szt0-DI_x2"
      },
      "source": [
        "plt.plot(loss_plot1[6])\n",
        "\n",
        "plt.xlim(0, 150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qoIgvuPJH0K"
      },
      "source": [
        "acc_per_fold2 = []\n",
        "loss_per_fold2 = []\n",
        "loss_plot2 = []\n",
        "kfold = KFold(n_splits= 10, shuffle=True,random_state = seed)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(z, f):\n",
        "\n",
        "  # Define the model architecture\n",
        "  inputs = Input(shape=(94, 85, 288))\n",
        "\n",
        "  aa = Conv2D(16, kernel_size=(3,3),strides=(1,1),activation='relu')(inputs) \n",
        "  aa = Conv2D(16, kernel_size=(3,3),strides=(1,1),activation='relu')(aa) \n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "\n",
        "  aa = Conv2D(32, kernel_size=(3,3),strides=(1,1),activation='relu')(aa) \n",
        "  aa = Conv2D(32, kernel_size=(3,3),strides=(1,1),activation='relu')(aa) \n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "\n",
        "  ff = Flatten()(aa)\n",
        "\n",
        "  #hidden layer\n",
        "  hh = Dense(160,activation='relu')(ff) \n",
        "  hh = Dropout(0.2)(hh)\n",
        "\n",
        "  #output layer\n",
        "  output1 = Dense(1, activation='linear', name='TGM_T_1')(hh)\n",
        "\n",
        "\n",
        "\n",
        "  model2 = Model(inputs = inputs , outputs = [output1])\n",
        "\n",
        "  # compiling the sequential model\n",
        "  opt = Adagrad()\n",
        "  model2.compile(loss='mse', optimizer=opt, metrics=[nrmse])\n",
        "\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  nabh2 = model2.fit(z[train], f[train],batch_size=8, epochs=150,verbose=0)\n",
        "\n",
        "  loss_train2 = (nabh2.history['nrmse'])\n",
        "\n",
        "  epochs2 = range(0,150)\n",
        "  sns.set() # Use seaborn's default style to make attractive graphs\n",
        "  plt.rcParams['figure.dpi'] = 340 \n",
        "  plt.plot(epochs2, loss_train2, 'g', label=f'Fold {fold_no}')\n",
        "\n",
        "  plt.title('loss vs epoch')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model2.evaluate(z[test], f[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}%')\n",
        "  acc_per_fold2.append(scores[1])\n",
        "  loss_per_fold2.append(scores[0])\n",
        "  loss_plot2.append(nabh2.history['nrmse'])\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold2)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold2[i]} - Mape: {acc_per_fold2[i]}%')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Average scores for all folds:')\n",
        "  print(f'> Mape: {np.mean(acc_per_fold2)} (+- {np.std(acc_per_fold2)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold2)}')\n",
        "  print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSFG9J2KL0sh"
      },
      "source": [
        "m2 = model2.predict(X_test)\n",
        "m2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAQY89xQMZZ_"
      },
      "source": [
        "Y3_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwUaNQdyMaYc"
      },
      "source": [
        "plt.plot(range(0,750),'r')\n",
        "plt.scatter(m2,Y3_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm9M-QZsMfZD"
      },
      "source": [
        "r2 = r2_score(Y3_test,m2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imn4b2ZQMk7Z"
      },
      "source": [
        "r2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DED35faVMlos"
      },
      "source": [
        "import scipy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCswqrLnMo--"
      },
      "source": [
        "scipy.stats.spearmanr(m2,Y3_test).correlation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sggGrw6IMypn"
      },
      "source": [
        "plt.plot(loss_plot2[2])\n",
        "\n",
        "plt.xlim(0, 150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfMTC_bx9ExA"
      },
      "source": [
        "plt.rcParams['figure.facecolor'] = 'cyan'\n",
        "plt.plot(epochs, loss_plot[6], 'k-.', label=f'Mp', lw=2.6)\n",
        "plt.plot(epochs1, loss_plot1[6], 'r--', label=f'Dw', lw=3)\n",
        "plt.plot(epochs2, loss_plot2[2], 'g', label=f'T', lw = 3.2)\n",
        "plt.title('loss(nrmse) vs epoch')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmFGiZfw93at"
      },
      "source": [
        "acc_per_fold3 = []\n",
        "loss_per_fold3 = []\n",
        "Mp_fold = []\n",
        "kfold = KFold(n_splits= 10, shuffle=True,random_state = seed)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(z, y):\n",
        "\n",
        "  # Define the model architecture\n",
        "  inputs = Input(shape=(94, 85, 288))\n",
        "\n",
        "  # convolutional layer\n",
        "\n",
        "  aa = Conv2D(16, kernel_size=(1,1),strides=(1,1),activation='relu')(inputs)\n",
        "  aa = Conv2D(16, kernel_size=(3,3),strides=(1,1),activation='relu')(aa)\n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "\n",
        "  aa = Conv2D(32, kernel_size=(3,3),strides=(1,1),activation='relu')(aa)\n",
        "  aa = Conv2D(32, kernel_size=(3,3),strides=(1,1),activation='relu')(aa)\n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "  \n",
        "  \n",
        "  ff = Flatten()(aa)\n",
        "\n",
        "  # hidden layer\n",
        "  hh = Dense(160,activation='relu')(ff)\n",
        "  hh = Dropout(0.2)(hh)\n",
        "  # output layer\n",
        "  output1 = Dense(1, activation='linear', name='TGM_T_1')(hh)\n",
        "\n",
        "\n",
        "\n",
        "  model3 = Model(inputs = inputs , outputs = [output1])\n",
        "\n",
        "  # compiling the sequential model\n",
        "  opt = Adagrad()\n",
        "  model3.compile(loss='mse', optimizer=opt, metrics=[nrmse])\n",
        "\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  nabh3 = model3.fit(z[train], y[train],batch_size=8, epochs=100,verbose=0)\n",
        "  loss_train = nabh3.history['nrmse']\n",
        "  \n",
        "  epochs = range(0,100)\n",
        "  sns.set() # Use seaborn's default style to make attractive graphs\n",
        "  plt.rcParams['figure.dpi'] = 340 \n",
        "  \n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model3.evaluate(z[test], y[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model3.metrics_names[0]} of {scores[0]}; {model3.metrics_names[1]} of {scores[1]}%')\n",
        "  acc_per_fold3.append(scores[1])\n",
        "  loss_per_fold3.append(scores[0])\n",
        "  \n",
        "  Mp_fold.append(f'Fold {fold_no}')\n",
        "  m3 = model3.predict(X_train)\n",
        "  r3 = r2_score(Y1_train,m3)\n",
        "  s3 = scipy.stats.spearmanr(m3,Y1_train).correlation\n",
        "  \n",
        "  if fold_no==0:\n",
        "    m3s = pd.DataFrame(np.column_stack([Mp_fold, r3, s3]), columns=[f'Fold_Mp', f'pear_corr', f'spear_corr'], index = False)\n",
        "    m3s.to_csv('corre_Mp.csv')\n",
        "  else:\n",
        "    m3s = pd.DataFrame(np.column_stack([Mp_fold, r3, s3])) \n",
        "    m3s.to_csv('corre_Mp.csv', mode='a')\n",
        "  # Increase fold number\n",
        "  Mp_fold.pop()\n",
        "  fold_no = fold_no + 1\n",
        " \n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold3)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold3[i]} - Mape: {acc_per_fold3[i]}%')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Average scores for all folds:')\n",
        "  print(f'> Mape: {np.mean(acc_per_fold3)} (+- {np.std(acc_per_fold3)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold3)}')\n",
        "  print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSvd8hnT8tdI"
      },
      "source": [
        "acc_per_fold4 = []\n",
        "loss_per_fold4 = []\n",
        "Dw_plot = []\n",
        "kfold = KFold(n_splits= 10, shuffle=True,random_state = seed)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(z, en):\n",
        "\n",
        "  # Define the model architecture\n",
        "  inputs = Input(shape=(94, 85, 288))\n",
        "\n",
        "  # convolutional layer\n",
        "\n",
        "  aa = Conv2D(8, kernel_size=(1,1),strides=(1,1),activation='relu')(inputs) \n",
        "  aa = Conv2D(8, kernel_size=(1,1),strides=(1,1),activation='relu')(aa) \n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "\n",
        "  aa = Conv2D(16, kernel_size=(1,1),strides=(1,1),activation='relu')(aa) \n",
        "  aa = Conv2D(16, kernel_size=(1,1),strides=(1,1),activation='relu')(aa) \n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "\n",
        "  ff = Flatten()(aa)\n",
        "\n",
        "  #hidden layer\n",
        "  hh = Dense(140,activation='relu')(ff) \n",
        "  hh = Dropout(0.2)(hh)\n",
        "\n",
        "  #output layer\n",
        "  output1 = Dense(1, activation='linear', name='TGM_T_1')(hh)\n",
        "\n",
        "  model4 = Model(inputs = inputs , outputs = [output1])\n",
        "\n",
        "  #compiling the sequential model\n",
        "  opt = Adam() \n",
        "  model4.compile(loss='mse', optimizer=opt, metrics=[nrmse])\n",
        "\n",
        "  #Generate a print\n",
        "  print('------------------------------------------------------------------------') \n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  nabh4 = model4.fit(z[train], en[train],batch_size=8, epochs=150,verbose=0)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model4.evaluate(z[test], en[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model4.metrics_names[0]} of {scores[0]}; {model4.metrics_names[1]} of {scores[1]}%')\n",
        "  acc_per_fold4.append(scores[1])\n",
        "  loss_per_fold4.append(scores[0])\n",
        "\n",
        "  Dw_plot.append(f'Fold {fold_no}')\n",
        "  m4 = model4.predict(X_train)\n",
        "  r4 = r2_score(Y2_train/1e-9,m4)\n",
        "  s4 = scipy.stats.spearmanr(m4,Y2_train/1e-9).correlation\n",
        "  \n",
        "  if fold_no==0:\n",
        "    m4s = pd.DataFrame(np.column_stack([Dw_plot, r4, s4]), columns=[f'Fold_Dw', f'pear_corr', f'spear_corr'], index = False)\n",
        "    m4s.to_csv('corre_Dw.csv')\n",
        "  else:\n",
        "    m4s = pd.DataFrame(np.column_stack([Dw_plot, r4, s4])) \n",
        "    m4s.to_csv('corre_Dw.csv', mode='a')\n",
        "  # Increase fold number\n",
        "  Dw_plot.pop()\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold4)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold4[i]} - Mape: {acc_per_fold4[i]}%')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Average scores for all folds:')\n",
        "  print(f'> Mape: {np.mean(acc_per_fold4)} (+- {np.std(acc_per_fold4)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold4)}')\n",
        "  print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz2NCEC_DcxU"
      },
      "source": [
        "acc_per_fold5 = []\n",
        "loss_per_fold5 = []\n",
        "T_fold = []\n",
        "kfold = KFold(n_splits= 10, shuffle=True,random_state = seed)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(z, f):\n",
        "\n",
        "  # Define the model architecture\n",
        "  inputs = Input(shape=(94, 85, 288))\n",
        "\n",
        "  aa = Conv2D(16, kernel_size=(3,3),strides=(1,1),activation='relu')(inputs) \n",
        "  aa = Conv2D(16, kernel_size=(3,3),strides=(1,1),activation='relu')(aa) \n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "\n",
        "  aa = Conv2D(32, kernel_size=(3,3),strides=(1,1),activation='relu')(aa) \n",
        "  aa = Conv2D(32, kernel_size=(3,3),strides=(1,1),activation='relu')(aa) \n",
        "  aa = MaxPooling2D(pool_size=(2,2))(aa)\n",
        "\n",
        "  ff = Flatten()(aa)\n",
        "\n",
        "  #hidden layer\n",
        "  hh = Dense(160,activation='relu')(ff) \n",
        "  hh = Dropout(0.2)(hh)\n",
        "\n",
        "  #output layer\n",
        "  output1 = Dense(1, activation='linear', name='TGM_T_1')(hh)\n",
        "\n",
        "\n",
        "\n",
        "  model5 = Model(inputs = inputs , outputs = [output1])\n",
        "\n",
        "  # compiling the sequential model\n",
        "  opt = Adagrad()\n",
        "  model5.compile(loss='mse', optimizer=opt, metrics=[nrmse])\n",
        "\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  nabh5 = model5.fit(z[train], f[train],batch_size=8, epochs=150,verbose=0)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model5.evaluate(z[test], f[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model5.metrics_names[0]} of {scores[0]}; {model5.metrics_names[1]} of {scores[1]}%')\n",
        "  acc_per_fold5.append(scores[1])\n",
        "  loss_per_fold5.append(scores[0])\n",
        "  \n",
        "  T_fold.append(f'Fold {fold_no}')\n",
        "  m5 = model5.predict(X_train)\n",
        "  r5 = r2_score(Y3_train,m5)\n",
        "  s5 = scipy.stats.spearmanr(m5,Y3_train).correlation\n",
        "  \n",
        "  if fold_no==0:\n",
        "    m5s = pd.DataFrame(np.column_stack([T_fold, r5, s5]), columns=[f'Fold_T', f'pear_corr', f'spear_corr'], index = False)\n",
        "    m5s.to_csv('corre_T.csv')\n",
        "  else:\n",
        "    m5s = pd.DataFrame(np.column_stack([T_fold, r5, s5])) \n",
        "    m5s.to_csv('corre_T.csv', mode='a')\n",
        "  # Increase fold number\n",
        "  T_fold.pop()\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold5)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold5[i]} - Mape: {acc_per_fold5[i]}%')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Average scores for all folds:')\n",
        "  print(f'> Mape: {np.mean(acc_per_fold5)} (+- {np.std(acc_per_fold5)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold5)}')\n",
        "  print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY0KL0jlQw-3"
      },
      "source": [
        "df = pd.read_csv('CORRELATION_VALUES.csv')\n",
        "\n",
        "plt.rcParams['figure.facecolor'] = 'cyan'\n",
        "\n",
        "plt.title('Correlation Distribution for 10 folds')\n",
        "\n",
        "sns.boxplot( x=[df[\"Pearson_T\"],df[\"Spearman_T\"], df[\"Pearson_Dw\"],df[\"Spearman_Dw\"], df[\"Pearson_Mp\"],df[\"Spearman_Mp\"]],y=['Pearson_T','Spearman_T','Pearson_Dw','Spearman_Dw','Pearson_Mp','Spearman_Mp'], width = 0.5 ).set(\n",
        "    xlabel='Correlation Values')\n",
        "#plt.ylim(0.970, 1.00)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aIlteihiWN7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}